{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2L1W8EQffV1Bkqp4qm2TS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PremKarhale/Full-stack-using-Agentic-AI-/blob/main/Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating AI Agent (Random quote generator)"
      ],
      "metadata": {
        "id": "WFgmsp4UO8Ms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pDQ7bgIuO7ct",
        "outputId": "8cc9e127-1477-45a6-f2b9-61a336a76af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.4/719.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.4/157.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.48.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# step 1 (install dependencies)\n",
        "!pip install langchain langchain-google-genai -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2 (import Required libraries )\n",
        "import requests\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "TDg7OwbOPhgc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 (Define a Custom tool Randomquote)\n",
        "@tool\n",
        "def Randomquote_generator()->str:\n",
        "  \"\"\" IT Fetches random inspirational quotes using zenquotes Api\"\"\"\n",
        "  url =\"https://zenquotes.io/api/random\"\n",
        "  response = requests.get(url)\n",
        "  data = response.json()\n",
        "  return (f\"{data[0]['q']}-{data[0]['a']}\")\n"
      ],
      "metadata": {
        "id": "vvk_ifNbQSyA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 :( set up a gemini model)\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\" , api_key = api_key)\n"
      ],
      "metadata": {
        "id": "D3pZt2MnTQkm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5 :create Agent\n",
        "agent = create_agent(\n",
        "    llm,\n",
        "    tools=[Randomquote_generator],\n",
        "    system_prompt=\"You are a helpfull assistance ,Use tools only when needed oterwise answer naturally \"\n",
        ")"
      ],
      "metadata": {
        "id": "BcezAkvrTeAa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 : invoke Agent\n",
        "while True :\n",
        "  prompt = input(\"Enter Message :\")\n",
        "  if prompt ==\"exit\":\n",
        "    break;\n",
        "  response = agent.invoke({\n",
        "      \"messages\":[{\"role\":\"user\",\"content\":prompt}]\n",
        "  })\n",
        "  result = response[\"messages\"][-1].content\n",
        "  print(f\"AI : {result}\")\n",
        "\n",
        "print(response['messages'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_YJDrN4Yfh6",
        "outputId": "1c4c7daa-a302-46f9-f54c-5b5dc5a9f3c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Message :generate me a random quote\n",
            "AI : The most difficult thing is the decision to act, the rest is merely tenacity. The fears are paper tigers.-Amelia Earhart\n",
            "Enter Message :give me a quote \n",
            "AI : An ounce of performance is worth pounds of promises.-Mae West\n",
            "Enter Message :exit\n",
            "[HumanMessage(content='give me a quote ', additional_kwargs={}, response_metadata={}, id='f95f958e-909c-409e-8aee-eaec2d7604c9'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'Randomquote_generator', 'arguments': '{}'}, '__gemini_function_call_thought_signatures__': {'4b756631-3fea-48fa-bfea-a3ef4cebf062': 'CvoBAXLI2nxhJDOGmTjINhNNKWDpOu6SevsRy15AKtTwtO9zuCKKZFwAyjssfB+r8zWx3joXGZf29AU1nthbKnzRzKTHFyhfHiRy7WJZROVx1UVy/k+VV07dyT1tMzcfGbgFCpUJXb6/Ctk2ilDTkOWg2aAkyKVqh9//WFJ75+4r50KLs68fdtKEw4iaTzXX6/3RZ50NmeJW3DObs/5YglzNO2QTgZkK/8y3gBxVYD9/kPHfCAJXTQ2lsWqL1c5l+F2IIgaSqk7TXsGR4kycjVLtuE63/VlARDFxwj5Fm3NACPZ73NEnWNlCjPmM6vt29AP3yMeU3r4MdI1K4w=='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c05ea-5118-75e1-9137-f92df77922b4-0', tool_calls=[{'name': 'Randomquote_generator', 'args': {}, 'id': '4b756631-3fea-48fa-bfea-a3ef4cebf062', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 58, 'total_tokens': 114, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 47}}), ToolMessage(content='An ounce of performance is worth pounds of promises.-Mae West', name='Randomquote_generator', id='257d4923-66b9-43c7-bfe2-16ca3016e59c', tool_call_id='4b756631-3fea-48fa-bfea-a3ef4cebf062'), AIMessage(content='An ounce of performance is worth pounds of promises.-Mae West', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c05ea-54cf-77f2-a694-dbbfc30b980e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 94, 'output_tokens': 12, 'total_tokens': 106, 'input_token_details': {'cache_read': 0}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0Fd6BfjbPdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}